{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "812f3c61",
   "metadata": {},
   "source": [
    "# MIDAS Heart/Resp Motion Pipeline\n",
    "\n",
    "This notebook separates respiratory and cardiac motion, detects beats, and builds\n",
    "time-series features for grouping into four conditions (control, doxo, doxo+epa, other).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29219679",
   "metadata": {},
   "source": [
    "## 0) Setup\n",
    "\n",
    "We use the video frame rate as the sampling rate for time-series analysis.\n",
    "At 60 fps, each beat has only ~3-4 samples for a 270-310 bpm heart rate.\n",
    "This limits beat-shape fidelity and makes morphology comparisons unreliable.\n",
    "\n",
    "Respiration is controlled; set RESP_CPM_RANGE to lock a narrow resp band.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e346623",
   "metadata": {},
   "source": [
    "## Saved figures\n",
    "All plots are saved to `../outputs/figures/` as PNGs for later review.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49665f54",
   "metadata": {},
   "source": [
    "## Sampling limitations limitations\n",
    "\n",
    "At 60 fps and 270-310 bpm, each beat has ~11-13 samples.\n",
    "This is better for beat-shape clustering, but morphology detail is still moderate.\n",
    "We keep those sections for reference, but record-level features remain stable, and beat-level shape is more feasible at 60 fps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea245523",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T18:39:08.971518Z",
     "iopub.status.busy": "2026-01-11T18:39:08.971222Z",
     "iopub.status.idle": "2026-01-11T18:39:14.260143Z",
     "shell.execute_reply": "2026-01-11T18:39:14.259759Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from scipy.signal import butter, sosfiltfilt, welch, find_peaks, hilbert, detrend\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "from sklearn.model_selection import GroupKFold, cross_val_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score\n",
    "\n",
    "try:\n",
    "    from sktime.transformations.panel.rocket import MiniRocket\n",
    "except Exception:\n",
    "    MiniRocket = None\n",
    "\n",
    "try:\n",
    "    import hdbscan\n",
    "except Exception:\n",
    "    hdbscan = None\n",
    "\n",
    "try:\n",
    "    from umap import UMAP\n",
    "except Exception:\n",
    "    UMAP = None\n",
    "\n",
    "try:\n",
    "    from tslearn.clustering import KShape\n",
    "    from tslearn.preprocessing import TimeSeriesScalerMeanVariance\n",
    "except Exception:\n",
    "    KShape = None\n",
    "    TimeSeriesScalerMeanVariance = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c4ca13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T18:39:14.261793Z",
     "iopub.status.busy": "2026-01-11T18:39:14.261512Z",
     "iopub.status.idle": "2026-01-11T18:39:14.266030Z",
     "shell.execute_reply": "2026-01-11T18:39:14.265803Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"../data\")\n",
    "FIG_DIR = Path(\"../outputs/figures\")\n",
    "FIG_DPI = 150\n",
    "FRAME_RATE_FPS = 60.0\n",
    "USE_FRAME_RATE = True\n",
    "RESP_CPM_RANGE = (70.0, 80.0)\n",
    "RESP_BAND_HZ = (1.0, 1.5)\n",
    "RESP_PLOT_BAND_HZ = (0.6, 1.6)\n",
    "RESP_SEPARATION_BAND_HZ = None\n",
    "RESP_DECOMP_CUTOFF_HZ = 2.0\n",
    "MIN_BPM = 270\n",
    "MAX_BPM = 310\n",
    "HEART_BAND_HZ = (MIN_BPM / 60.0, MAX_BPM / 60.0)\n",
    "HEART_BAND_WIDE_HZ = (4.0, 6.5)\n",
    "HEART_SEPARATION_BAND_HZ = HEART_BAND_WIDE_HZ\n",
    "HEART_DECOMP_BAND_HZ = HEART_BAND_HZ\n",
    "HEART_DETECT_BAND_HZ = HEART_BAND_HZ\n",
    "HEART_USE_RESP_RESIDUAL = True\n",
    "HEART_DETECT_USE_RESIDUAL = True\n",
    "HEART_DETECT_METHOD = \"filter\"\n",
    "SEPARATION_METHOD = \"filter\"\n",
    "DECOMPOSITION_METHOD = \"fft\"\n",
    "DECOMPOSITION_OUTPUT_TAG = \"filter\"\n",
    "RESP_CYCLES_OUTPUT_TAG = \"filter\"\n",
    "REFRACTORY_S = 0.85 * (60.0 / MAX_BPM)\n",
    "BEAT_WINDOW_S = (0.3 * (60.0 / MIN_BPM), 0.7 * (60.0 / MIN_BPM))\n",
    "ENV_SMOOTH_S = 0.02\n",
    "BEAT_PROMINENCE = 0.8\n",
    "RESP_MIN_PERIOD_S = 0.7\n",
    "RESP_SMOOTH_S = 0.1\n",
    "RESP_PROMINENCE_FACTOR = 0.5\n",
    "RESP_PLOT_TRIM_S = 1.0\n",
    "ZOOM_START_S = 10.0\n",
    "ZOOM_DURATION_S = 10.0\n",
    "RESAMPLE_LEN = 256\n",
    "MAX_BEATS_PER_RECORD = 60\n",
    "BEAT_SAMPLE_SEED = 0\n",
    "BEATS_PER_SEGMENTS = (5, 10)\n",
    "SEGMENT_STRIDE = 1\n",
    "SEGMENT_BEAT_PROMINENCE = 0.1\n",
    "\n",
    "def fft_isolate_band(signal: np.ndarray, fs: float, low_bpm: float, high_bpm: float) -> np.ndarray:\n",
    "    n = len(signal)\n",
    "    freqs = np.fft.rfftfreq(n, d=1.0/fs)\n",
    "    fft_vals = np.fft.rfft(signal)\n",
    "    mask = (freqs >= low_bpm/60.0) & (freqs <= high_bpm/60.0)\n",
    "    filtered_fft = np.zeros_like(fft_vals)\n",
    "    filtered_fft[mask] = fft_vals[mask]\n",
    "    return np.fft.irfft(filtered_fft, n=n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2728c91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T18:39:14.267162Z",
     "iopub.status.busy": "2026-01-11T18:39:14.267070Z",
     "iopub.status.idle": "2026-01-11T18:39:14.268910Z",
     "shell.execute_reply": "2026-01-11T18:39:14.268696Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_fig(name: str, out_dir: Path | None = None) -> None:\n",
    "    target_dir = FIG_DIR if out_dir is None else out_dir\n",
    "    target_dir.mkdir(parents=True, exist_ok=True)\n",
    "    plt.savefig(target_dir / name, dpi=FIG_DPI, bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b4d67d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T18:39:14.269989Z",
     "iopub.status.busy": "2026-01-11T18:39:14.269918Z",
     "iopub.status.idle": "2026-01-11T18:39:14.272106Z",
     "shell.execute_reply": "2026-01-11T18:39:14.271876Z"
    }
   },
   "outputs": [],
   "source": [
    "def resp_band_from_target() -> tuple[float, float]:\n",
    "    if RESP_SEPARATION_BAND_HZ is not None:\n",
    "        return RESP_SEPARATION_BAND_HZ\n",
    "    if RESP_CPM_RANGE is None:\n",
    "        return RESP_BAND_HZ\n",
    "    low_bpm, high_bpm = RESP_CPM_RANGE\n",
    "    return (max(0.01, low_bpm / 60.0), high_bpm / 60.0)\n",
    "\n",
    "\n",
    "def resp_band_for_cycles() -> tuple[float, float]:\n",
    "    if RESP_CPM_RANGE is None:\n",
    "        return resp_band_from_target()\n",
    "    low_bpm, high_bpm = RESP_CPM_RANGE\n",
    "    return (max(0.01, low_bpm / 60.0), high_bpm / 60.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d6a588",
   "metadata": {},
   "source": [
    "## Expected heart rate range\n",
    "\n",
    "Targeting 270-310 bpm (~4.5-5.2 Hz). We set a tight heart band and\n",
    "derive refractory period and beat window sizes from this range.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d173479",
   "metadata": {},
   "source": [
    "## 1) Load data and estimate sampling rate\n",
    "\n",
    "If `USE_FRAME_RATE` is enabled, the time column is ignored and time is reconstructed\n",
    "from the constant frame rate. This avoids mislabeled or inconsistent timestamps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9246a81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T18:39:14.273363Z",
     "iopub.status.busy": "2026-01-11T18:39:14.273288Z",
     "iopub.status.idle": "2026-01-11T18:39:14.316457Z",
     "shell.execute_reply": "2026-01-11T18:39:14.316146Z"
    }
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Record:\n",
    "    path: Path\n",
    "    label: str\n",
    "    time_s: np.ndarray\n",
    "    signal: np.ndarray\n",
    "    fs: float\n",
    "    group_id: str\n",
    "\n",
    "\n",
    "def label_from_name(name: str) -> str:\n",
    "    lower = name.lower()\n",
    "    if lower.startswith(\"control\"):\n",
    "        return \"control\"\n",
    "    if lower.startswith(\"empa_doxo\") or lower.startswith(\"preconditionare_empa_doxo\"):\n",
    "        return \"empa_doxo\"\n",
    "    if lower.startswith(\"doxo\") or lower.startswith(\"doxo_re\"):\n",
    "        return \"doxo\"\n",
    "    if lower.startswith(\"empa\"):\n",
    "        return \"empa\"\n",
    "    return \"other\"\n",
    "\n",
    "\n",
    "def load_records(data_dir: Path) -> list[Record]:\n",
    "    records: list[Record] = []\n",
    "    for path in sorted(data_dir.glob(\"*.csv\")):\n",
    "        df = pd.read_csv(path)\n",
    "        signal = df.iloc[:, 1].to_numpy(dtype=float)\n",
    "        if USE_FRAME_RATE:\n",
    "            fs = FRAME_RATE_FPS\n",
    "            time_s = np.arange(len(signal)) / fs\n",
    "        else:\n",
    "            time_s = df.iloc[:, 0].to_numpy(dtype=float)\n",
    "            dt = np.diff(time_s)\n",
    "            fs = 1.0 / float(np.median(dt)) if len(dt) else 0.0\n",
    "        records.append(\n",
    "            Record(\n",
    "                path=path,\n",
    "                label=label_from_name(path.stem),\n",
    "                time_s=time_s,\n",
    "                signal=signal,\n",
    "                fs=fs,\n",
    "                group_id=path.stem,\n",
    "            )\n",
    "        )\n",
    "    return records\n",
    "\n",
    "\n",
    "records = load_records(DATA_DIR)\n",
    "{rec.path.name: rec.fs for rec in records}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c86631c",
   "metadata": {},
   "source": [
    "## 2) Spectrum inspection (Welch PSD)\n",
    "\n",
    "Use PSD to confirm the heart-band peak is present and separated from respiration.\n",
    "At low sampling rates, the heart band sits near Nyquist and can be noisy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586d9a37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T18:39:14.317890Z",
     "iopub.status.busy": "2026-01-11T18:39:14.317774Z",
     "iopub.status.idle": "2026-01-11T18:39:14.697306Z",
     "shell.execute_reply": "2026-01-11T18:39:14.696976Z"
    }
   },
   "outputs": [],
   "source": [
    "rec = records[0]\n",
    "f, pxx = welch(rec.signal, fs=rec.fs, nperseg=min(2048, len(rec.signal)))\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.semilogy(f, pxx)\n",
    "plt.title(f\"PSD: {rec.path.name}\")\n",
    "plt.xlabel(\"Hz\")\n",
    "plt.ylabel(\"Power\")\n",
    "plt.xlim(0, 20)\n",
    "save_fig(f\"psd_{rec.path.stem}.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c7a613",
   "metadata": {},
   "source": [
    "## 2c) Rough HR estimation via PSD peak\n",
    "At 60 fps, beat shapes are under-sampled, but the PSD peak can still provide\n",
    "a rough heart-rate estimate. This uses frequency-domain energy only.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1eb6e2",
   "metadata": {},
   "source": [
    "## 2b) Fourier decomposition (FFT masking)\n",
    "\n",
    "FFT masking provides a quick split, but can introduce ringing and boundary artifacts.\n",
    "Compare with filter-based separation if results look distorted.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e11375d",
   "metadata": {},
   "source": [
    "## 3) Separate respiration and heart (zero-phase filtering)\n",
    "\n",
    "Zero-phase filters reduce timing shifts, which is critical for beat detection.\n",
    "With low fps, keep the band narrow and avoid aggressive filtering.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc1be1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T18:39:14.698906Z",
     "iopub.status.busy": "2026-01-11T18:39:14.698813Z",
     "iopub.status.idle": "2026-01-11T18:39:14.709118Z",
     "shell.execute_reply": "2026-01-11T18:39:14.708831Z"
    }
   },
   "outputs": [],
   "source": [
    "def band_limits(band: tuple[float, float], fs: float) -> tuple[float, float]:\n",
    "    low, high = band\n",
    "    nyq = fs / 2.0\n",
    "    return (max(0.01, low), min(high, 0.95 * nyq))\n",
    "\n",
    "\n",
    "def butter_sos(band: tuple[float, float], fs: float, order: int = 4) -> np.ndarray:\n",
    "    low, high = band_limits(band, fs)\n",
    "    return butter(order, [low, high], btype=\"bandpass\", fs=fs, output=\"sos\")\n",
    "\n",
    "\n",
    "def lowpass_sos(cutoff: float, fs: float, order: int = 4) -> np.ndarray:\n",
    "    cutoff = min(cutoff, 0.95 * (fs / 2.0))\n",
    "    return butter(order, cutoff, btype=\"lowpass\", fs=fs, output=\"sos\")\n",
    "\n",
    "\n",
    "def fft_bandpass(signal: np.ndarray, fs: float, band: tuple[float, float]) -> np.ndarray:\n",
    "    n = len(signal)\n",
    "    freqs = np.fft.rfftfreq(n, d=1.0 / fs)\n",
    "    fft_vals = np.fft.rfft(signal)\n",
    "    low, high = band\n",
    "    mask = (freqs >= low) & (freqs <= high)\n",
    "    filtered_fft = np.where(mask, fft_vals, 0)\n",
    "    return np.fft.irfft(filtered_fft, n=n)\n",
    "\n",
    "\n",
    "def zoom_window(time_s: np.ndarray) -> tuple[float, float]:\n",
    "    start = ZOOM_START_S\n",
    "    end = ZOOM_START_S + ZOOM_DURATION_S\n",
    "    if len(time_s) == 0:\n",
    "        return (start, end)\n",
    "    end = min(end, float(time_s[-1]))\n",
    "    return (start, end)\n",
    "\n",
    "\n",
    "def zoom_mask(time_s: np.ndarray) -> np.ndarray:\n",
    "    start = ZOOM_START_S\n",
    "    end = ZOOM_START_S + ZOOM_DURATION_S\n",
    "    if len(time_s) == 0:\n",
    "        return np.array([], dtype=bool)\n",
    "    end = min(end, float(time_s[-1]))\n",
    "    return (time_s >= start) & (time_s <= end)\n",
    "\n",
    "\n",
    "def preprocess_signal(signal: np.ndarray) -> np.ndarray:\n",
    "    return detrend(signal, type=\"linear\")\n",
    "\n",
    "\n",
    "def separate_components(signal: np.ndarray, fs: float, method: str = \"filter\") -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Separates respiratory and heart components using band-limited filtering.\n",
    "    Respiration is removed from the heart channel by default.\n",
    "    \"\"\"\n",
    "    signal = preprocess_signal(signal)\n",
    "    resp_band = RESP_PLOT_BAND_HZ if RESP_PLOT_BAND_HZ is not None else resp_band_from_target()\n",
    "    heart_band = HEART_SEPARATION_BAND_HZ\n",
    "\n",
    "    if method == \"fft\":\n",
    "        resp = fft_bandpass(signal, fs, resp_band)\n",
    "        source = signal - resp if HEART_USE_RESP_RESIDUAL else signal\n",
    "        heart = fft_bandpass(source, fs, heart_band)\n",
    "        return resp, heart\n",
    "    if method == \"filter\":\n",
    "        resp_sos = butter_sos(resp_band, fs)\n",
    "        resp = sosfiltfilt(resp_sos, signal)\n",
    "        source = signal - resp if HEART_USE_RESP_RESIDUAL else signal\n",
    "        heart_sos = butter_sos(heart_band, fs)\n",
    "        heart = sosfiltfilt(heart_sos, source)\n",
    "        return resp, heart\n",
    "    raise ValueError(f\"Unknown separation method: {method}\")\n",
    "\n",
    "\n",
    "def decompose_for_plot(signal: np.ndarray, fs: float, method: str) -> tuple[np.ndarray, np.ndarray]:\n",
    "    signal = preprocess_signal(signal)\n",
    "    resp_band = RESP_PLOT_BAND_HZ if RESP_PLOT_BAND_HZ is not None else resp_band_from_target()\n",
    "    if method == \"fft\":\n",
    "        resp = fft_bandpass(signal, fs, resp_band)\n",
    "        source = signal - resp\n",
    "        heart = fft_bandpass(source, fs, HEART_DECOMP_BAND_HZ)\n",
    "        return resp, heart\n",
    "\n",
    "    resp_sos = butter_sos(resp_band, fs)\n",
    "    resp = sosfiltfilt(resp_sos, signal)\n",
    "    source = signal - resp\n",
    "    heart_sos = butter_sos(HEART_DECOMP_BAND_HZ, fs)\n",
    "    heart = sosfiltfilt(heart_sos, source)\n",
    "    return resp, heart\n",
    "\n",
    "\n",
    "def extract_resp_for_cycles(signal: np.ndarray, fs: float) -> np.ndarray:\n",
    "    signal = preprocess_signal(signal)\n",
    "    resp_band = resp_band_for_cycles()\n",
    "    resp_sos = butter_sos(resp_band, fs)\n",
    "    return sosfiltfilt(resp_sos, signal)\n",
    "\n",
    "\n",
    "def extract_heart_for_beats(signal: np.ndarray, fs: float) -> np.ndarray:\n",
    "    signal = preprocess_signal(signal)\n",
    "    resp_band = RESP_PLOT_BAND_HZ if RESP_PLOT_BAND_HZ is not None else resp_band_from_target()\n",
    "    source = signal\n",
    "    if HEART_DETECT_USE_RESIDUAL:\n",
    "        resp_sos = butter_sos(resp_band, fs)\n",
    "        resp = sosfiltfilt(resp_sos, signal)\n",
    "        source = signal - resp\n",
    "\n",
    "    heart_sos = butter_sos(HEART_DETECT_BAND_HZ, fs)\n",
    "    return sosfiltfilt(heart_sos, source)\n",
    "\n",
    "\n",
    "def detect_beats_for_segments(heart: np.ndarray, fs: float) -> np.ndarray:\n",
    "    heart_norm = (heart - np.median(heart)) / (np.median(np.abs(heart - np.median(heart))) + 1e-9)\n",
    "    min_dist = int(REFRACTORY_S * fs)\n",
    "    peaks, _ = find_peaks(heart_norm, distance=min_dist, prominence=SEGMENT_BEAT_PROMINENCE)\n",
    "    return peaks\n",
    "\n",
    "\n",
    "def detect_beats(heart: np.ndarray, fs: float) -> tuple[np.ndarray, np.ndarray]:\n",
    "    heart_norm = (heart - np.median(heart)) / (np.median(np.abs(heart - np.median(heart))) + 1e-9)\n",
    "\n",
    "    min_dist = int(REFRACTORY_S * fs)\n",
    "    peaks, _ = find_peaks(heart_norm, distance=min_dist, prominence=BEAT_PROMINENCE)\n",
    "    return peaks, heart_norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d47331",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T18:39:14.710456Z",
     "iopub.status.busy": "2026-01-11T18:39:14.710354Z",
     "iopub.status.idle": "2026-01-11T18:39:15.197535Z",
     "shell.execute_reply": "2026-01-11T18:39:15.197213Z"
    }
   },
   "outputs": [],
   "source": [
    "rec = records[0]\n",
    "resp_fft, heart_fft = decompose_for_plot(rec.signal, rec.fs, method=\"fft\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(10, 6))\n",
    "axes[0].plot(rec.time_s, rec.signal, label=\"raw\", alpha=0.5)\n",
    "axes[0].plot(rec.time_s, resp_fft, label=\"resp (smart fft)\")\n",
    "axes[0].plot(rec.time_s, heart_fft, label=\"heart (fft band)\")\n",
    "axes[0].legend()\n",
    "axes[0].set_title(f\"FFT decomposition: {rec.path.name} (full)\")\n",
    "axes[0].set_xlabel(\"Time (s)\")\n",
    "\n",
    "mask = zoom_mask(rec.time_s)\n",
    "axes[1].plot(rec.time_s[mask], rec.signal[mask], label=\"raw\", alpha=0.5)\n",
    "axes[1].plot(rec.time_s[mask], resp_fft[mask], label=\"resp (smart fft)\")\n",
    "axes[1].plot(rec.time_s[mask], heart_fft[mask], label=\"heart (fft band)\")\n",
    "axes[1].legend()\n",
    "axes[1].set_title(\"FFT decomposition (zoom)\")\n",
    "axes[1].set_xlabel(\"Time (s)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "save_fig(f\"fft_decomposition_{rec.path.stem}.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291a8e1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T18:39:15.199229Z",
     "iopub.status.busy": "2026-01-11T18:39:15.199110Z",
     "iopub.status.idle": "2026-01-11T18:39:15.263683Z",
     "shell.execute_reply": "2026-01-11T18:39:15.263059Z"
    }
   },
   "outputs": [],
   "source": [
    "def estimate_hr_psd(signal: np.ndarray, fs: float, band: tuple[float, float], method: str) -> float | None:\n",
    "    heart = extract_heart_for_beats(signal, fs)\n",
    "    f, pxx = welch(heart, fs=fs, nperseg=min(2048, len(heart)))\n",
    "    low, high = band\n",
    "    mask = (f >= low) & (f <= high)\n",
    "    if not np.any(mask):\n",
    "        return None\n",
    "    idx = np.argmax(pxx[mask])\n",
    "    peak_hz = f[mask][idx]\n",
    "    return 60.0 * peak_hz\n",
    "\n",
    "\n",
    "hr_psd = []\n",
    "for rec in records:\n",
    "    hr = estimate_hr_psd(rec.signal, rec.fs, HEART_BAND_HZ, SEPARATION_METHOD)\n",
    "    hr_psd.append(hr)\n",
    "\n",
    "print(\"PSD HR (bpm):\", [round(h, 1) if h else None for h in hr_psd])\n",
    "if any(h is not None for h in hr_psd):\n",
    "    arr = np.array([h for h in hr_psd if h is not None])\n",
    "    print(f\"PSD HR summary: mean={arr.mean():.1f}, median={np.median(arr):.1f}, min={arr.min():.1f}, max={arr.max():.1f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c7c912",
   "metadata": {},
   "source": [
    "## 3b) Decomposition plots by category\n",
    "\n",
    "We plot one representative file per category to compare component separation.\n",
    "If components look similar across categories, clustering will be difficult.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f13204e",
   "metadata": {},
   "source": [
    "## 3c) Respiratory cycle timing (full cycle + inhale/exhale)\n",
    "We estimate respiration cycle durations from the low-frequency component.\n",
    "At 60 fps this is reliable because respiration is slow and periodic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cefc59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T18:39:15.288936Z",
     "iopub.status.busy": "2026-01-11T18:39:15.288791Z",
     "iopub.status.idle": "2026-01-11T18:39:15.380548Z",
     "shell.execute_reply": "2026-01-11T18:39:15.379118Z"
    }
   },
   "outputs": [],
   "source": [
    "def smooth_signal(signal: np.ndarray, fs: float, window_s: float) -> np.ndarray:\n",
    "    window = max(1, int(window_s * fs))\n",
    "    if window <= 1:\n",
    "        return signal\n",
    "    kernel = np.ones(window) / window\n",
    "    return np.convolve(signal, kernel, mode=\"same\")\n",
    "\n",
    "\n",
    "def analyze_resp_cycles(resp: np.ndarray, fs: float) -> dict:\n",
    "    resp_smoothed = smooth_signal(resp, fs, RESP_SMOOTH_S)\n",
    "    resp_min_period_s = RESP_MIN_PERIOD_S\n",
    "    if RESP_CPM_RANGE is not None:\n",
    "        resp_min_period_s = 0.7 * (60.0 / max(RESP_CPM_RANGE))\n",
    "    distance = max(1, int(resp_min_period_s * fs))\n",
    "    median = np.median(resp_smoothed)\n",
    "    mad = np.median(np.abs(resp_smoothed - median)) + 1e-9\n",
    "    prominence = mad * RESP_PROMINENCE_FACTOR\n",
    "\n",
    "    peaks, _ = find_peaks(resp_smoothed, distance=distance, prominence=prominence)\n",
    "    troughs, _ = find_peaks(-resp_smoothed, distance=distance, prominence=prominence)\n",
    "\n",
    "    peaks_t = peaks / fs\n",
    "    troughs_t = troughs / fs\n",
    "\n",
    "    full_cycles = np.diff(peaks_t).tolist() if len(peaks_t) > 1 else []\n",
    "    inhalations = []\n",
    "    exhalations = []\n",
    "\n",
    "    for peak_t in peaks_t:\n",
    "        prev_troughs = troughs_t[troughs_t < peak_t]\n",
    "        next_troughs = troughs_t[troughs_t > peak_t]\n",
    "        if len(prev_troughs) > 0:\n",
    "            inhalations.append(float(peak_t - prev_troughs[-1]))\n",
    "        if len(next_troughs) > 0:\n",
    "            exhalations.append(float(next_troughs[0] - peak_t))\n",
    "\n",
    "    return {\n",
    "        \"resp_smoothed\": resp_smoothed,\n",
    "        \"peaks\": peaks,\n",
    "        \"troughs\": troughs,\n",
    "        \"full_cycle_s\": full_cycles,\n",
    "        \"inhalation_s\": inhalations,\n",
    "        \"exhalation_s\": exhalations,\n",
    "    }\n",
    "\n",
    "\n",
    "for rec in records:\n",
    "    resp, _ = separate_components(rec.signal, rec.fs, method=SEPARATION_METHOD)\n",
    "    metrics = analyze_resp_cycles(resp, rec.fs)\n",
    "    full_cycle = metrics[\"full_cycle_s\"]\n",
    "    inhale = metrics[\"inhalation_s\"]\n",
    "    exhale = metrics[\"exhalation_s\"]\n",
    "    if full_cycle:\n",
    "        print(f\"{rec.path.name} full cycle: mean={np.mean(full_cycle):.2f}s, median={np.median(full_cycle):.2f}s\")\n",
    "        if RESP_CPM_RANGE is not None:\n",
    "            expected_period = 60.0 / (sum(RESP_CPM_RANGE) / 2.0)\n",
    "            delta = np.mean(full_cycle) - expected_period\n",
    "            print(f\"{rec.path.name} cycle delta vs expected: {delta:+.2f}s\")\n",
    "    if inhale:\n",
    "        print(f\"{rec.path.name} inhalation: mean={np.mean(inhale):.2f}s, median={np.median(inhale):.2f}s\")\n",
    "    if exhale:\n",
    "        print(f\"{rec.path.name} exhalation: mean={np.mean(exhale):.2f}s, median={np.median(exhale):.2f}s\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b36f8b",
   "metadata": {},
   "source": [
    "## 3d) Respiratory cycle visualization by category\n",
    "Plots the smoothed respiratory signal with detected peaks and troughs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b0a3a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T18:39:15.386103Z",
     "iopub.status.busy": "2026-01-11T18:39:15.385747Z",
     "iopub.status.idle": "2026-01-11T18:39:16.486248Z",
     "shell.execute_reply": "2026-01-11T18:39:16.485902Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_resp_cycles_by_category(records: list[Record], method: str, output_tag: str) -> None:\n",
    "    grouped: dict[str, list[Record]] = {}\n",
    "    for rec in records:\n",
    "        grouped.setdefault(rec.label, []).append(rec)\n",
    "\n",
    "    labels = sorted(grouped.keys())\n",
    "    fig, axes = plt.subplots(len(labels), 2, figsize=(14, 3.2 * len(labels)))\n",
    "    if len(labels) == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for row, label in enumerate(labels):\n",
    "        rec = grouped[label][0]\n",
    "        resp_full = extract_resp_for_cycles(rec.signal, rec.fs)\n",
    "        trim = int(RESP_PLOT_TRIM_S * rec.fs)\n",
    "        if trim * 2 < len(resp_full):\n",
    "            resp = resp_full[trim:-trim]\n",
    "            time_s = rec.time_s[trim:-trim]\n",
    "        else:\n",
    "            resp = resp_full\n",
    "            time_s = rec.time_s\n",
    "        metrics = analyze_resp_cycles(resp, rec.fs)\n",
    "        resp_smoothed = metrics[\"resp_smoothed\"]\n",
    "        full_ax = axes[row][0]\n",
    "        zoom_ax = axes[row][1]\n",
    "        full_ax.plot(time_s, resp_smoothed, label=\"resp (smoothed)\")\n",
    "        full_ax.plot(time_s[metrics[\"peaks\"]], resp_smoothed[metrics[\"peaks\"]], \"g^\", label=\"peaks\")\n",
    "        full_ax.plot(time_s[metrics[\"troughs\"]], resp_smoothed[metrics[\"troughs\"]], \"rv\", label=\"troughs\")\n",
    "        full_ax.set_title(f\"{label}: {rec.path.name} (full)\")\n",
    "        full_ax.set_xlabel(\"Time (s)\")\n",
    "        full_ax.legend()\n",
    "\n",
    "        mask = zoom_mask(time_s)\n",
    "        start, end = zoom_window(time_s)\n",
    "        peaks_zoom = metrics[\"peaks\"][(time_s[metrics[\"peaks\"]] >= start) & (time_s[metrics[\"peaks\"]] <= end)]\n",
    "        troughs_zoom = metrics[\"troughs\"][(time_s[metrics[\"troughs\"]] >= start) & (time_s[metrics[\"troughs\"]] <= end)]\n",
    "        zoom_ax.plot(time_s[mask], resp_smoothed[mask], label=\"resp (smoothed)\")\n",
    "        zoom_ax.plot(time_s[peaks_zoom], resp_smoothed[peaks_zoom], \"g^\", label=\"peaks\")\n",
    "        zoom_ax.plot(time_s[troughs_zoom], resp_smoothed[troughs_zoom], \"rv\", label=\"troughs\")\n",
    "        zoom_ax.set_title(\"Zoom\")\n",
    "        zoom_ax.set_xlabel(\"Time (s)\")\n",
    "        zoom_ax.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    save_fig(f\"resp_cycles_by_category_{output_tag}.png\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_resp_cycles_by_category(records, DECOMPOSITION_METHOD, RESP_CYCLES_OUTPUT_TAG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05177a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T18:39:16.488123Z",
     "iopub.status.busy": "2026-01-11T18:39:16.488038Z",
     "iopub.status.idle": "2026-01-11T18:39:18.016359Z",
     "shell.execute_reply": "2026-01-11T18:39:18.016043Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_category_decomposition(records: list[Record], method: str, output_tag: str) -> None:\n",
    "    grouped: dict[str, list[Record]] = {}\n",
    "    for rec in records:\n",
    "        grouped.setdefault(rec.label, []).append(rec)\n",
    "\n",
    "    labels = sorted(grouped.keys())\n",
    "    fig, axes = plt.subplots(len(labels), 2, figsize=(14, 3.2 * len(labels)))\n",
    "    if len(labels) == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for row, label in enumerate(labels):\n",
    "        rec = grouped[label][0]\n",
    "        resp, heart = decompose_for_plot(rec.signal, rec.fs, method=method)\n",
    "        full_ax = axes[row][0]\n",
    "        zoom_ax = axes[row][1]\n",
    "        full_ax.plot(rec.time_s, rec.signal, label=\"raw\", alpha=0.4)\n",
    "        full_ax.plot(rec.time_s, resp, label=\"resp\")\n",
    "        full_ax.plot(rec.time_s, heart, label=\"heart\")\n",
    "        full_ax.set_title(f\"{label}: {rec.path.name} (full)\")\n",
    "        full_ax.set_xlabel(\"Time (s)\")\n",
    "        full_ax.legend()\n",
    "\n",
    "        mask = zoom_mask(rec.time_s)\n",
    "        zoom_ax.plot(rec.time_s[mask], rec.signal[mask], label=\"raw\", alpha=0.4)\n",
    "        zoom_ax.plot(rec.time_s[mask], resp[mask], label=\"resp\")\n",
    "        zoom_ax.plot(rec.time_s[mask], heart[mask], label=\"heart\")\n",
    "        zoom_ax.set_title(\"Zoom\")\n",
    "        zoom_ax.set_xlabel(\"Time (s)\")\n",
    "        zoom_ax.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    save_fig(f\"decomposition_by_category_{output_tag}.png\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plot_category_decomposition(records, DECOMPOSITION_METHOD, DECOMPOSITION_OUTPUT_TAG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b159de",
   "metadata": {},
   "source": [
    "## 4) Beat detection on heart component\n",
    "\n",
    "Beat picking uses the heart-band envelope with a refractory period and robust prominence.\n",
    "At 60 fps, beat timing is adequate for HR estimation and basic morphology.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b172b071",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T18:39:18.017948Z",
     "iopub.status.busy": "2026-01-11T18:39:18.017854Z",
     "iopub.status.idle": "2026-01-11T18:39:18.302001Z",
     "shell.execute_reply": "2026-01-11T18:39:18.301602Z"
    }
   },
   "outputs": [],
   "source": [
    "rec = records[0]\n",
    "heart = extract_heart_for_beats(rec.signal, rec.fs)\n",
    "peaks, heart_norm = detect_beats(heart, rec.fs)\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(10, 6))\n",
    "axes[0].plot(rec.time_s, heart_norm, label=\"heart (normalized)\")\n",
    "axes[0].plot(rec.time_s[peaks], heart_norm[peaks], \"rx\", label=\"beats\")\n",
    "axes[0].legend()\n",
    "axes[0].set_title(f\"Beat detection: {rec.path.name} (full)\")\n",
    "axes[0].set_xlabel(\"Time (s)\")\n",
    "\n",
    "mask = zoom_mask(rec.time_s)\n",
    "start, end = zoom_window(rec.time_s)\n",
    "peaks_zoom = peaks[(rec.time_s[peaks] >= start) & (rec.time_s[peaks] <= end)]\n",
    "axes[1].plot(rec.time_s[mask], heart_norm[mask], label=\"heart (normalized)\")\n",
    "axes[1].plot(rec.time_s[peaks_zoom], heart_norm[peaks_zoom], \"rx\", label=\"beats\")\n",
    "axes[1].legend()\n",
    "axes[1].set_title(\"Beat detection (zoom)\")\n",
    "axes[1].set_xlabel(\"Time (s)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "save_fig(f\"beat_detection_{rec.path.stem}.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f5793b",
   "metadata": {},
   "source": [
    "## 4b) Beat detection visualization by category\n",
    "\n",
    "These plots show envelope peaks for one file per category.\n",
    "Check for consistent peak spacing and absence of respiratory leakage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d822dea9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T18:39:18.303547Z",
     "iopub.status.busy": "2026-01-11T18:39:18.303442Z",
     "iopub.status.idle": "2026-01-11T18:39:19.434309Z",
     "shell.execute_reply": "2026-01-11T18:39:19.433950Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_category_beats(records: list[Record], method: str) -> None:\n",
    "    grouped: dict[str, list[Record]] = {}\n",
    "    for rec in records:\n",
    "        grouped.setdefault(rec.label, []).append(rec)\n",
    "\n",
    "    labels = sorted(grouped.keys())\n",
    "    fig, axes = plt.subplots(len(labels), 2, figsize=(14, 3.2 * len(labels)))\n",
    "    if len(labels) == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for row, label in enumerate(labels):\n",
    "        rec = grouped[label][0]\n",
    "        heart = extract_heart_for_beats(rec.signal, rec.fs)\n",
    "        peaks, heart_norm = detect_beats(heart, rec.fs)\n",
    "        full_ax = axes[row][0]\n",
    "        zoom_ax = axes[row][1]\n",
    "        full_ax.plot(rec.time_s, heart_norm, label=\"heart (normalized)\")\n",
    "        full_ax.plot(rec.time_s[peaks], heart_norm[peaks], \"rx\", label=\"beats\")\n",
    "        full_ax.set_title(f\"{label}: {rec.path.name} (full)\")\n",
    "        full_ax.set_xlabel(\"Time (s)\")\n",
    "        full_ax.legend()\n",
    "\n",
    "        mask = zoom_mask(rec.time_s)\n",
    "        start, end = zoom_window(rec.time_s)\n",
    "        peaks_zoom = peaks[(rec.time_s[peaks] >= start) & (rec.time_s[peaks] <= end)]\n",
    "        zoom_ax.plot(rec.time_s[mask], heart_norm[mask], label=\"heart (normalized)\")\n",
    "        zoom_ax.plot(rec.time_s[peaks_zoom], heart_norm[peaks_zoom], \"rx\", label=\"beats\")\n",
    "        zoom_ax.set_title(\"Zoom\")\n",
    "        zoom_ax.set_xlabel(\"Time (s)\")\n",
    "        zoom_ax.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    save_fig(f\"beat_detection_by_category_{method}.png\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_category_beats(records, SEPARATION_METHOD)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50583d2",
   "metadata": {},
   "source": [
    "## 4c) HR estimate from detected beats\n",
    "Cross-check BPM from envelope peaks (median inter-beat interval).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3718a3e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T18:39:19.436133Z",
     "iopub.status.busy": "2026-01-11T18:39:19.436040Z",
     "iopub.status.idle": "2026-01-11T18:39:19.500568Z",
     "shell.execute_reply": "2026-01-11T18:39:19.499048Z"
    }
   },
   "outputs": [],
   "source": [
    "def estimate_hr_peaks(signal: np.ndarray, fs: float) -> float | None:\n",
    "    heart = extract_heart_for_beats(signal, fs)\n",
    "    peaks, _ = detect_beats(heart, fs)\n",
    "    if len(peaks) < 2:\n",
    "        return None\n",
    "    intervals = np.diff(peaks) / fs\n",
    "    return 60.0 / float(np.median(intervals))\n",
    "\n",
    "\n",
    "hr_peaks = []\n",
    "for rec in records:\n",
    "    hr = estimate_hr_peaks(rec.signal, rec.fs)\n",
    "    hr_peaks.append(hr)\n",
    "\n",
    "print(\"Peak HR (bpm):\", [round(h, 1) if h else None for h in hr_peaks])\n",
    "if any(h is not None for h in hr_peaks):\n",
    "    arr = np.array([h for h in hr_peaks if h is not None])\n",
    "    print(f\"Peak HR summary: mean={arr.mean():.1f}, median={np.median(arr):.1f}, min={arr.min():.1f}, max={arr.max():.1f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d3878c",
   "metadata": {},
   "source": [
    "## 5) Extract beat windows (fixed length)\n",
    "\n",
    "Beat windows are resampled to a fixed length for feature extraction.\n",
    "At 60 fps, windows contain very few raw samples, limiting shape fidelity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb2b6c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T18:39:19.516121Z",
     "iopub.status.busy": "2026-01-11T18:39:19.515830Z",
     "iopub.status.idle": "2026-01-11T18:39:19.560178Z",
     "shell.execute_reply": "2026-01-11T18:39:19.559440Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_beat_windows(\n",
    "    signal: np.ndarray,\n",
    "    peaks: np.ndarray,\n",
    "    fs: float,\n",
    "    window_s: tuple[float, float],\n",
    "    resample_len: int,\n",
    ") -> list[np.ndarray]:\n",
    "    pre_s, post_s = window_s\n",
    "    pre = int(pre_s * fs)\n",
    "    post = int(post_s * fs)\n",
    "    windows: list[np.ndarray] = []\n",
    "    for peak in peaks:\n",
    "        start = peak - pre\n",
    "        end = peak + post\n",
    "        if start < 0 or end >= len(signal):\n",
    "            continue\n",
    "        snippet = signal[start:end]\n",
    "        x_old = np.linspace(0.0, 1.0, num=len(snippet), endpoint=False)\n",
    "        x_new = np.linspace(0.0, 1.0, num=resample_len, endpoint=False)\n",
    "        windows.append(np.interp(x_new, x_old, snippet))\n",
    "    return windows\n",
    "\n",
    "\n",
    "beat_windows = extract_beat_windows(heart, peaks, rec.fs, BEAT_WINDOW_S, RESAMPLE_LEN)\n",
    "len(beat_windows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d12ff2",
   "metadata": {},
   "source": [
    "## Ground-truth groups (from filenames)\n",
    "\n",
    "Labels are derived from filename prefixes only and are used **only** for evaluation. Clustering models do not see these labels during fitting. The four target groups are:\n",
    "\n",
    "- control\n",
    "- doxo (including doxo_re)\n",
    "- empa\n",
    "- empa_doxo (including preconditionare_empa_doxo)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f3bd11",
   "metadata": {},
   "source": [
    "## 6) Build dataset (beats -> features -> grouping)\n",
    "\n",
    "We build beat-level samples and labels for evaluation only.\n",
    "Clustering is unsupervised; labels are used strictly for post-hoc metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d464cc94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T18:39:19.572814Z",
     "iopub.status.busy": "2026-01-11T18:39:19.572536Z",
     "iopub.status.idle": "2026-01-11T18:39:19.863477Z",
     "shell.execute_reply": "2026-01-11T18:39:19.862356Z"
    }
   },
   "outputs": [],
   "source": [
    "beats: list[np.ndarray] = []\n",
    "labels: list[str] = []\n",
    "record_ids: list[str] = []\n",
    "\n",
    "rng = np.random.default_rng(BEAT_SAMPLE_SEED)\n",
    "\n",
    "for rec in records:\n",
    "    heart = extract_heart_for_beats(rec.signal, rec.fs)\n",
    "    peaks, _ = detect_beats(heart, rec.fs)\n",
    "    windows = extract_beat_windows(heart, peaks, rec.fs, BEAT_WINDOW_S, RESAMPLE_LEN)\n",
    "    if MAX_BEATS_PER_RECORD and len(windows) > MAX_BEATS_PER_RECORD:\n",
    "        idx = rng.choice(len(windows), size=MAX_BEATS_PER_RECORD, replace=False)\n",
    "        windows = [windows[i] for i in idx]\n",
    "    beats.extend(windows)\n",
    "    labels.extend([rec.label] * len(windows))\n",
    "    record_ids.extend([rec.group_id] * len(windows))\n",
    "\n",
    "X = np.stack(beats) if beats else np.empty((0, RESAMPLE_LEN))\n",
    "y = np.array(labels)\n",
    "record_ids = np.array(record_ids)\n",
    "X.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360cb872",
   "metadata": {},
   "source": [
    "## 7) MiniROCKET baseline (supervised)\n",
    "\n",
    "This is a supervised baseline to gauge separability. It is not used for clustering.\n",
    "Low accuracy suggests limited signal at beat level.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be134cc6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T18:39:19.866971Z",
     "iopub.status.busy": "2026-01-11T18:39:19.866294Z",
     "iopub.status.idle": "2026-01-11T18:39:22.077486Z",
     "shell.execute_reply": "2026-01-11T18:39:22.076505Z"
    }
   },
   "outputs": [],
   "source": [
    "if MiniRocket is None or len(X) == 0:\n",
    "    print(\"MiniRocket not available or no beats extracted.\")\n",
    "else:\n",
    "    X3d = X[:, np.newaxis, :]\n",
    "    rocket = MiniRocket()\n",
    "    X_feat = rocket.fit_transform(X3d)\n",
    "    if hasattr(X_feat, \"to_numpy\"):\n",
    "        X_feat = X_feat.to_numpy()\n",
    "    clf = RidgeClassifierCV(alphas=np.logspace(-3, 3, 7))\n",
    "    unique_groups = np.unique(record_ids)\n",
    "    if len(unique_groups) >= 3:\n",
    "        splits = GroupKFold(n_splits=min(5, len(unique_groups))).split(X_feat, y, record_ids)\n",
    "        scores = cross_val_score(clf, X_feat, y, cv=splits)\n",
    "        print(f\"Group CV accuracy: {scores.mean():.3f} +/- {scores.std():.3f}\")\n",
    "    else:\n",
    "        clf.fit(X_feat, y)\n",
    "        print(\"Trained on full data (insufficient groups for CV).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f328036d",
   "metadata": {},
   "source": [
    "## 8) Clustering options (exploratory)\n",
    "\n",
    "Clustering uses beat-level features without labels; metrics are computed after fitting.\n",
    "At 60 fps, expect weak separation because beats are under-sampled.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ab41c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T18:39:22.082668Z",
     "iopub.status.busy": "2026-01-11T18:39:22.082510Z",
     "iopub.status.idle": "2026-01-11T18:39:47.450295Z",
     "shell.execute_reply": "2026-01-11T18:39:47.448022Z"
    }
   },
   "outputs": [],
   "source": [
    "def z_normalize_beats(x: np.ndarray) -> np.ndarray:\n",
    "    median = np.median(x, axis=1, keepdims=True)\n",
    "    mad = np.median(np.abs(x - median), axis=1, keepdims=True) + 1e-9\n",
    "    return (x - median) / mad\n",
    "\n",
    "\n",
    "def evaluate_clustering(y_true: np.ndarray, y_pred: np.ndarray, label: str) -> dict:\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "    if len(y_true) == 0 or len(np.unique(y_pred)) < 2:\n",
    "        print(f\"{label}: insufficient clusters for evaluation.\")\n",
    "        return {}\n",
    "\n",
    "    ari = adjusted_rand_score(y_true, y_pred)\n",
    "    nmi = normalized_mutual_info_score(y_true, y_pred)\n",
    "\n",
    "    true_labels = sorted(set(y_true))\n",
    "    pred_labels = sorted(set(y_pred))\n",
    "    true_map = {lab: idx for idx, lab in enumerate(true_labels)}\n",
    "    pred_map = {lab: idx for idx, lab in enumerate(pred_labels)}\n",
    "    contingency = np.zeros((len(true_labels), len(pred_labels)), dtype=int)\n",
    "    for t, p in zip(y_true, y_pred):\n",
    "        contingency[true_map[t], pred_map[p]] += 1\n",
    "    row_ind, col_ind = linear_sum_assignment(-contingency)\n",
    "    matched = contingency[row_ind, col_ind].sum()\n",
    "    best_acc = matched / len(y_true)\n",
    "    mapping = {pred_labels[c]: true_labels[r] for r, c in zip(row_ind, col_ind)}\n",
    "\n",
    "    print(f\"{label} ARI: {ari:.3f} | NMI: {nmi:.3f} | purity: {best_acc:.3f}\")\n",
    "    print(f\"{label} mapping (cluster -> label): {mapping}\")\n",
    "    print(pd.crosstab(pd.Series(y_pred, name=\"cluster\"), pd.Series(y_true, name=\"label\")))\n",
    "    return {\"clusters\": y_pred, \"mapping\": mapping, \"purity\": best_acc}\n",
    "\n",
    "\n",
    "if len(X) == 0:\n",
    "    print(\"No beats extracted for clustering.\")\n",
    "else:\n",
    "    X_norm = z_normalize_beats(X)\n",
    "    pca = PCA(n_components=min(10, X_norm.shape[1]))\n",
    "    X_pca = pca.fit_transform(X_norm)\n",
    "\n",
    "    kmeans = KMeans(n_clusters=4, n_init=50, random_state=0)\n",
    "    beat_clusters = kmeans.fit_predict(X_pca)\n",
    "    evaluate_clustering(y, beat_clusters, label=\"Beat KMeans (PCA)\")\n",
    "\n",
    "    if MiniRocket is not None:\n",
    "        X3d = X_norm[:, np.newaxis, :]\n",
    "        rocket = MiniRocket()\n",
    "        X_feat = rocket.fit_transform(X3d)\n",
    "        if hasattr(X_feat, \"to_numpy\"):\n",
    "            X_feat = X_feat.to_numpy()\n",
    "        rocket_clusters = kmeans.fit_predict(X_feat)\n",
    "        evaluate_clustering(y, rocket_clusters, label=\"Beat KMeans (MiniROCKET)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a451a1",
   "metadata": {},
   "source": [
    "## 8c) Beat-sequence clustering (5â€“10 beats per segment)\n",
    "\n",
    "We split each recording into non-overlapping segments of N beats (N=5 or 10), cluster those segments, then evaluate how often segments map back to their source labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85fc6e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T18:39:47.453638Z",
     "iopub.status.busy": "2026-01-11T18:39:47.453473Z",
     "iopub.status.idle": "2026-01-11T18:40:10.958882Z",
     "shell.execute_reply": "2026-01-11T18:40:10.957747Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_beat_segments(windows: list[np.ndarray], beats_per_segment: int, stride: int | None = None) -> list[np.ndarray]:\n",
    "    if beats_per_segment <= 0:\n",
    "        return []\n",
    "    if stride is None:\n",
    "        stride = beats_per_segment\n",
    "    segments = []\n",
    "    for start in range(0, len(windows) - beats_per_segment + 1, stride):\n",
    "        chunk = windows[start:start + beats_per_segment]\n",
    "        segments.append(np.concatenate(chunk))\n",
    "    return segments\n",
    "\n",
    "def per_category_accuracy(y_true: np.ndarray, y_pred: np.ndarray, mapping: dict) -> tuple[float, dict]:\n",
    "    mapped = np.array([mapping.get(p, None) for p in y_pred])\n",
    "    overall = float(np.mean(mapped == y_true)) if len(y_true) else 0.0\n",
    "    per_cat = {}\n",
    "    for lab in sorted(set(y_true)):\n",
    "        mask = y_true == lab\n",
    "        correct = int(np.sum(mapped[mask] == lab))\n",
    "        total = int(np.sum(mask))\n",
    "        per_cat[lab] = {\"correct\": correct, \"total\": total, \"acc\": (correct / total) if total else 0.0}\n",
    "    return overall, per_cat\n",
    "\n",
    "for beats_per_segment in BEATS_PER_SEGMENTS:\n",
    "    segments: list[np.ndarray] = []\n",
    "    seg_labels: list[str] = []\n",
    "    for rec in records:\n",
    "        heart = extract_heart_for_beats(rec.signal, rec.fs)\n",
    "        peaks = detect_beats_for_segments(heart, rec.fs)\n",
    "        windows = extract_beat_windows(heart, peaks, rec.fs, BEAT_WINDOW_S, RESAMPLE_LEN)\n",
    "        segs = build_beat_segments(windows, beats_per_segment, SEGMENT_STRIDE)\n",
    "        segments.extend(segs)\n",
    "        seg_labels.extend([rec.label] * len(segs))\n",
    "\n",
    "    X_seg = np.stack(segments) if segments else np.empty((0, beats_per_segment * RESAMPLE_LEN))\n",
    "    y_seg = np.array(seg_labels)\n",
    "\n",
    "    print(f\"\\nSegment size: {beats_per_segment} beats\")\n",
    "    print(f\"Total segments: {len(y_seg)}\")\n",
    "    if len(X_seg) == 0:\n",
    "        print(\"No segments for clustering.\")\n",
    "        continue\n",
    "    if len(X_seg) < 4:\n",
    "        print(f\"Not enough segments for 4 clusters (n={len(X_seg)}).\")\n",
    "        continue\n",
    "\n",
    "    X_seg_norm = z_normalize_beats(X_seg)\n",
    "    pca = PCA(n_components=min(10, X_seg_norm.shape[0], X_seg_norm.shape[1]))\n",
    "    X_seg_pca = pca.fit_transform(X_seg_norm)\n",
    "\n",
    "    kmeans = KMeans(n_clusters=4, n_init=50, random_state=0)\n",
    "    seg_clusters = kmeans.fit_predict(X_seg_pca)\n",
    "    result = evaluate_clustering(y_seg, seg_clusters, label=f\"Beat-seq KMeans (N={beats_per_segment})\")\n",
    "\n",
    "    if result:\n",
    "        overall, per_cat = per_category_accuracy(y_seg, seg_clusters, result[\"mapping\"])\n",
    "        print(f\"Overall accuracy (mapped): {overall:.3f}\")\n",
    "        for lab, stats in per_cat.items():\n",
    "            print(f\"  {lab}: {stats['correct']}/{stats['total']} = {stats['acc']:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd419fbe",
   "metadata": {},
   "source": [
    "## 8b) Beat-shape clustering with k-Shape\n",
    "\n",
    "k-Shape clusters by waveform shape. This is unreliable at 60 fps due to low samples per beat.\n",
    "Results are included for completeness but should not be over-interpreted.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ee4b15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T18:40:10.963138Z",
     "iopub.status.busy": "2026-01-11T18:40:10.962574Z",
     "iopub.status.idle": "2026-01-11T18:40:10.967272Z",
     "shell.execute_reply": "2026-01-11T18:40:10.966895Z"
    }
   },
   "outputs": [],
   "source": [
    "# k-Shape clustering removed for clarity; 60 fps yields limited beat shape detail.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d00356",
   "metadata": {},
   "source": [
    "## 9) Visualize clustering results\n",
    "\n",
    "Embedding plots compare ground truth vs clusters; overlap indicates weak separability.\n",
    "Use these for qualitative inspection, not as evidence of causality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc90c6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T18:40:10.970774Z",
     "iopub.status.busy": "2026-01-11T18:40:10.970650Z",
     "iopub.status.idle": "2026-01-11T18:40:16.050570Z",
     "shell.execute_reply": "2026-01-11T18:40:16.050224Z"
    }
   },
   "outputs": [],
   "source": [
    "if len(X) == 0:\n",
    "    print(\"No beats extracted for embedding.\")\n",
    "elif \"beat_clusters\" not in globals():\n",
    "    print(\"Run clustering before embedding.\")\n",
    "else:\n",
    "    X_norm = z_normalize_beats(X)\n",
    "    if UMAP is not None:\n",
    "        emb = UMAP(n_components=2, random_state=0).fit_transform(X_norm)\n",
    "    else:\n",
    "        emb = PCA(n_components=2).fit_transform(X_norm)\n",
    "\n",
    "    label_to_id = {lab: idx for idx, lab in enumerate(sorted(set(y)))}\n",
    "    y_ids = np.array([label_to_id[lab] for lab in y])\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "    axes[0].scatter(emb[:, 0], emb[:, 1], c=y_ids, cmap=\"tab10\", s=10)\n",
    "    axes[0].set_title(\"Ground truth labels\")\n",
    "    axes[1].scatter(emb[:, 0], emb[:, 1], c=beat_clusters, cmap=\"tab10\", s=10)\n",
    "    axes[1].set_title(\"Beat clusters\")\n",
    "    for ax in axes:\n",
    "        ax.set_xlabel(\"Dim 1\")\n",
    "        ax.set_ylabel(\"Dim 2\")\n",
    "    plt.tight_layout()\n",
    "    save_fig(\"embedding_labels_vs_clusters.png\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08da3d16",
   "metadata": {},
   "source": [
    "## 10) Record-level clustering (no label leakage)\n",
    "\n",
    "Aggregating beat features per recording can be more stable than beat-level clustering.\n",
    "This is the preferred unsupervised target when sampling is low.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb34244",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T18:40:16.052014Z",
     "iopub.status.busy": "2026-01-11T18:40:16.051901Z",
     "iopub.status.idle": "2026-01-11T18:40:16.136060Z",
     "shell.execute_reply": "2026-01-11T18:40:16.135628Z"
    }
   },
   "outputs": [],
   "source": [
    "if MiniRocket is None or len(X) == 0:\n",
    "    print(\"MiniRocket not available or no beats extracted.\")\n",
    "else:\n",
    "    X3d = X[:, np.newaxis, :]\n",
    "    if \"X_feat\" in globals():\n",
    "        features = X_feat\n",
    "    else:\n",
    "        rocket = MiniRocket()\n",
    "        features = rocket.fit_transform(X3d)\n",
    "    if hasattr(features, \"to_numpy\"):\n",
    "        features = features.to_numpy()\n",
    "\n",
    "    record_features = []\n",
    "    record_labels = []\n",
    "    record_names = []\n",
    "    for rec in records:\n",
    "        idx = np.where(record_ids == rec.group_id)[0]\n",
    "        if len(idx) == 0:\n",
    "            continue\n",
    "        record_features.append(features[idx].mean(axis=0))\n",
    "        record_labels.append(rec.label)\n",
    "        record_names.append(rec.group_id)\n",
    "\n",
    "    record_features = np.vstack(record_features)\n",
    "    record_labels = np.array(record_labels)\n",
    "\n",
    "    kmeans = KMeans(n_clusters=4, n_init=20, random_state=0)\n",
    "    record_clusters = kmeans.fit_predict(record_features)\n",
    "    evaluate_clustering(record_labels, record_clusters, label=\"Record-level KMeans\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09f4f62",
   "metadata": {},
   "source": [
    "## 10b) Record-level features (band power + PSD HR + HRV proxy)\n",
    "This uses record-level features that remain meaningful at 60 fps.\n",
    "It avoids beat-shape reliance and is preferred for clustering here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ae5feb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T18:40:16.138043Z",
     "iopub.status.busy": "2026-01-11T18:40:16.137896Z",
     "iopub.status.idle": "2026-01-11T18:40:16.361058Z",
     "shell.execute_reply": "2026-01-11T18:40:16.360210Z"
    }
   },
   "outputs": [],
   "source": [
    "def band_power(signal: np.ndarray, fs: float, band: tuple[float, float]) -> float:\n",
    "    f, pxx = welch(signal, fs=fs, nperseg=min(2048, len(signal)))\n",
    "    low, high = band\n",
    "    mask = (f >= low) & (f <= high)\n",
    "    if not np.any(mask):\n",
    "        return 0.0\n",
    "    return float(np.trapz(pxx[mask], f[mask]))\n",
    "\n",
    "\n",
    "record_features = []\n",
    "record_labels = []\n",
    "\n",
    "for rec in records:\n",
    "    resp_band = resp_band_from_target()\n",
    "    resp_power = band_power(rec.signal, rec.fs, resp_band)\n",
    "    heart_power = band_power(rec.signal, rec.fs, HEART_BAND_HZ)\n",
    "    hr_psd = estimate_hr_psd(rec.signal, rec.fs, HEART_BAND_HZ, SEPARATION_METHOD)\n",
    "\n",
    "    heart = extract_heart_for_beats(rec.signal, rec.fs)\n",
    "    peaks, _ = detect_beats(heart, rec.fs)\n",
    "    if len(peaks) >= 3:\n",
    "        intervals = np.diff(peaks) / rec.fs\n",
    "        hrv_proxy = float(np.std(intervals))\n",
    "    else:\n",
    "        hrv_proxy = 0.0\n",
    "\n",
    "    record_features.append([resp_power, heart_power, hr_psd or 0.0, hrv_proxy])\n",
    "    record_labels.append(rec.label)\n",
    "\n",
    "record_features = np.array(record_features)\n",
    "record_labels = np.array(record_labels)\n",
    "\n",
    "kmeans = KMeans(n_clusters=4, n_init=20, random_state=0)\n",
    "rec_clusters = kmeans.fit_predict(record_features)\n",
    "evaluate_clustering(record_labels, rec_clusters, label=\"Record features KMeans\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "validation_logs",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T18:40:16.365466Z",
     "iopub.status.busy": "2026-01-11T18:40:16.364994Z",
     "iopub.status.idle": "2026-01-11T18:40:16.566978Z",
     "shell.execute_reply": "2026-01-11T18:40:16.565048Z"
    }
   },
   "outputs": [],
   "source": [
    "def log_cycle_counts(record_name: str, duration_s: float, resp_peaks: int, heart_peaks: int) -> None:\n",
    "    \"\"\"\n",
    "    Logs validation metrics for detected cycles.\n",
    "    \"\"\"\n",
    "    resp_rate_bpm = (resp_peaks / duration_s) * 60.0\n",
    "    heart_rate_bpm = (heart_peaks / duration_s) * 60.0\n",
    "    \n",
    "    print(f\"File: {record_name:<35} | Duration: {duration_s:>5.2f}s\")\n",
    "    print(f\"  > Resp Cycles:  {resp_peaks:>3} (Rate: {resp_rate_bpm:>5.1f} cycles/min) [Target: 70-80]\")\n",
    "    print(f\"  > Heart Beats:  {heart_peaks:>3} (Rate: {heart_rate_bpm:>5.1f} beats/min)  [Target: 270-310]\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "\n",
    "print(\"\\n--- VALIDATION LOGS ---\\n\")\n",
    "for rec in records:\n",
    "    # 1. Separate components\n",
    "    resp, heart = separate_components(rec.signal, rec.fs, method=SEPARATION_METHOD)\n",
    "    \n",
    "    # 2. Detect peaks\n",
    "    # Resp peaks\n",
    "    resp_metrics = analyze_resp_cycles(resp, rec.fs)\n",
    "    n_resp_cycles = len(resp_metrics['peaks'])\n",
    "    \n",
    "    # Heart peaks\n",
    "    heart_peaks, _ = detect_beats(heart, rec.fs)\n",
    "    n_heart_beats = len(heart_peaks)\n",
    "    \n",
    "    # 3. Log results\n",
    "    duration = len(rec.signal) / rec.fs\n",
    "    log_cycle_counts(rec.path.name, duration, n_resp_cycles, n_heart_beats)\n",
    "\n",
    "def validate_rates(records: list[Record]) -> None:\n",
    "    print(\"\\n--- AUTOMATED RANGE CHECKS ---\\n\")\n",
    "    print(f\"{'File':<35} | {'Resp (70-80 cpm)':<15} | {'Heart (270-310)':<17} | {'Amp (resp/heart)':<17} | {'Status'}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for rec in records:\n",
    "        resp, heart = separate_components(rec.signal, rec.fs, method=SEPARATION_METHOD)\n",
    "        \n",
    "        # Get rates\n",
    "        resp_metrics = analyze_resp_cycles(resp, rec.fs)\n",
    "        n_resp = len(resp_metrics['peaks'])\n",
    "        duration = len(rec.signal) / rec.fs\n",
    "        resp_bpm = (n_resp / duration) * 60.0\n",
    "        \n",
    "        heart_peaks, _ = detect_beats(heart, rec.fs)\n",
    "        n_heart = len(heart_peaks)\n",
    "        heart_bpm = (n_heart / duration) * 60.0\n",
    "        \n",
    "        # Check ranges (strict expected bands)\n",
    "        resp_ok = 70.0 <= resp_bpm <= 80.0\n",
    "        heart_ok = 270.0 <= heart_bpm <= 310.0\n",
    "        \n",
    "        signal = preprocess_signal(rec.signal)\n",
    "        resp_lp = sosfiltfilt(lowpass_sos(RESP_DECOMP_CUTOFF_HZ, rec.fs), signal)\n",
    "        heart_bp = sosfiltfilt(butter_sos(HEART_DECOMP_BAND_HZ, rec.fs), signal)\n",
    "\n",
    "        resp_amp = float(np.ptp(resp_lp))\n",
    "        heart_amp = float(np.ptp(heart_bp))\n",
    "        amp_ratio = resp_amp / (heart_amp + 1e-9)\n",
    "        amp_ok = amp_ratio >= 1.0\n",
    "\n",
    "        status = \"PASS\" if (resp_ok and heart_ok and amp_ok) else \"CHECK\"\n",
    "        \n",
    "        print(f\"{rec.path.name:<35} | {resp_bpm:>5.1f} cpm {'OK' if resp_ok else 'X':<3}      | {heart_bpm:>5.1f} bpm {'OK' if heart_ok else 'X':<3}        | {amp_ratio:>6.2f} {'OK' if amp_ok else 'X':<3}       | {status}\")\n",
    "\n",
    "validate_rates(records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ce73bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T18:40:16.570890Z",
     "iopub.status.busy": "2026-01-11T18:40:16.570620Z",
     "iopub.status.idle": "2026-01-11T18:40:39.460629Z",
     "shell.execute_reply": "2026-01-11T18:40:39.459285Z"
    }
   },
   "outputs": [],
   "source": [
    "def record_fig_dir(rec: Record) -> Path:\n",
    "    return FIG_DIR / \"by_record\" / rec.path.stem\n",
    "\n",
    "\n",
    "def plot_record_psd(rec: Record, out_dir: Path) -> None:\n",
    "    f, pxx = welch(rec.signal, fs=rec.fs, nperseg=min(2048, len(rec.signal)))\n",
    "    fig, ax = plt.subplots(figsize=(8, 4))\n",
    "    ax.semilogy(f, pxx)\n",
    "    ax.set_title(f\"PSD: {rec.path.name}\")\n",
    "    ax.set_xlabel(\"Hz\")\n",
    "    ax.set_ylabel(\"Power\")\n",
    "    ax.set_xlim(0, 20)\n",
    "    plt.tight_layout()\n",
    "    save_fig(f\"psd_{rec.path.stem}.png\", out_dir=out_dir)\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def plot_record_fft_decomposition(rec: Record, out_dir: Path) -> None:\n",
    "    resp_fft, heart_fft = decompose_for_plot(rec.signal, rec.fs, method=\"fft\")\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(10, 6))\n",
    "    axes[0].plot(rec.time_s, rec.signal, label=\"raw\", alpha=0.5)\n",
    "    axes[0].plot(rec.time_s, resp_fft, label=\"resp (fft)\")\n",
    "    axes[0].plot(rec.time_s, heart_fft, label=\"heart (fft band)\")\n",
    "    axes[0].legend()\n",
    "    axes[0].set_title(f\"FFT decomposition: {rec.path.name} (full)\")\n",
    "    axes[0].set_xlabel(\"Time (s)\")\n",
    "\n",
    "    mask = zoom_mask(rec.time_s)\n",
    "    axes[1].plot(rec.time_s[mask], rec.signal[mask], label=\"raw\", alpha=0.5)\n",
    "    axes[1].plot(rec.time_s[mask], resp_fft[mask], label=\"resp (fft)\")\n",
    "    axes[1].plot(rec.time_s[mask], heart_fft[mask], label=\"heart (fft band)\")\n",
    "    axes[1].legend()\n",
    "    axes[1].set_title(\"FFT decomposition (zoom)\")\n",
    "    axes[1].set_xlabel(\"Time (s)\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    save_fig(f\"fft_decomposition_{rec.path.stem}.png\", out_dir=out_dir)\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def plot_record_decomposition(rec: Record, method: str, output_tag: str, out_dir: Path) -> None:\n",
    "    resp, heart = decompose_for_plot(rec.signal, rec.fs, method=method)\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "    axes[0].plot(rec.time_s, rec.signal, label=\"raw\", alpha=0.4)\n",
    "    axes[0].plot(rec.time_s, resp, label=\"resp\")\n",
    "    axes[0].plot(rec.time_s, heart, label=\"heart\")\n",
    "    axes[0].set_title(f\"{rec.path.name} (full)\")\n",
    "    axes[0].set_xlabel(\"Time (s)\")\n",
    "    axes[0].legend()\n",
    "\n",
    "    mask = zoom_mask(rec.time_s)\n",
    "    axes[1].plot(rec.time_s[mask], rec.signal[mask], label=\"raw\", alpha=0.4)\n",
    "    axes[1].plot(rec.time_s[mask], resp[mask], label=\"resp\")\n",
    "    axes[1].plot(rec.time_s[mask], heart[mask], label=\"heart\")\n",
    "    axes[1].set_title(\"Zoom\")\n",
    "    axes[1].set_xlabel(\"Time (s)\")\n",
    "    axes[1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    save_fig(f\"decomposition_{rec.path.stem}_{output_tag}.png\", out_dir=out_dir)\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def plot_record_beats(rec: Record, method: str, out_dir: Path) -> None:\n",
    "    heart = extract_heart_for_beats(rec.signal, rec.fs)\n",
    "    peaks, heart_norm = detect_beats(heart, rec.fs)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    axes[0].plot(rec.time_s, heart_norm, label=\"heart (normalized)\")\n",
    "    axes[0].plot(rec.time_s[peaks], heart_norm[peaks], \"rx\", label=\"beats\")\n",
    "    axes[0].set_title(f\"{rec.path.name} (full)\")\n",
    "    axes[0].set_xlabel(\"Time (s)\")\n",
    "    axes[0].legend()\n",
    "\n",
    "    mask = zoom_mask(rec.time_s)\n",
    "    start, end = zoom_window(rec.time_s)\n",
    "    peaks_zoom = peaks[(rec.time_s[peaks] >= start) & (rec.time_s[peaks] <= end)]\n",
    "    axes[1].plot(rec.time_s[mask], heart_norm[mask], label=\"heart (normalized)\")\n",
    "    axes[1].plot(rec.time_s[peaks_zoom], heart_norm[peaks_zoom], \"rx\", label=\"beats\")\n",
    "    axes[1].set_title(\"Zoom\")\n",
    "    axes[1].set_xlabel(\"Time (s)\")\n",
    "    axes[1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    save_fig(f\"beat_detection_{rec.path.stem}_{method}.png\", out_dir=out_dir)\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def plot_record_resp_cycles(rec: Record, output_tag: str, out_dir: Path) -> None:\n",
    "    resp_full = extract_resp_for_cycles(rec.signal, rec.fs)\n",
    "    trim = int(RESP_PLOT_TRIM_S * rec.fs)\n",
    "    if trim * 2 < len(resp_full):\n",
    "        resp = resp_full[trim:-trim]\n",
    "        time_s = rec.time_s[trim:-trim]\n",
    "    else:\n",
    "        resp = resp_full\n",
    "        time_s = rec.time_s\n",
    "    metrics = analyze_resp_cycles(resp, rec.fs)\n",
    "    resp_smoothed = metrics[\"resp_smoothed\"]\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    axes[0].plot(time_s, resp_smoothed, label=\"resp (smoothed)\")\n",
    "    axes[0].plot(time_s[metrics[\"peaks\"]], resp_smoothed[metrics[\"peaks\"]], \"g^\", label=\"peaks\")\n",
    "    axes[0].plot(time_s[metrics[\"troughs\"]], resp_smoothed[metrics[\"troughs\"]], \"rv\", label=\"troughs\")\n",
    "    axes[0].set_title(f\"{rec.path.name} (full)\")\n",
    "    axes[0].set_xlabel(\"Time (s)\")\n",
    "    axes[0].legend()\n",
    "\n",
    "    mask = zoom_mask(time_s)\n",
    "    start, end = zoom_window(time_s)\n",
    "    peaks_zoom = metrics[\"peaks\"][(time_s[metrics[\"peaks\"]] >= start) & (time_s[metrics[\"peaks\"]] <= end)]\n",
    "    troughs_zoom = metrics[\"troughs\"][(time_s[metrics[\"troughs\"]] >= start) & (time_s[metrics[\"troughs\"]] <= end)]\n",
    "    axes[1].plot(time_s[mask], resp_smoothed[mask], label=\"resp (smoothed)\")\n",
    "    axes[1].plot(time_s[peaks_zoom], resp_smoothed[peaks_zoom], \"g^\", label=\"peaks\")\n",
    "    axes[1].plot(time_s[troughs_zoom], resp_smoothed[troughs_zoom], \"rv\", label=\"troughs\")\n",
    "    axes[1].set_title(\"Zoom\")\n",
    "    axes[1].set_xlabel(\"Time (s)\")\n",
    "    axes[1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    save_fig(f\"resp_cycles_{rec.path.stem}_{output_tag}.png\", out_dir=out_dir)\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def export_all_record_figures(records: list[Record]) -> None:\n",
    "    for rec in records:\n",
    "        out_dir = record_fig_dir(rec)\n",
    "        plot_record_psd(rec, out_dir)\n",
    "        plot_record_fft_decomposition(rec, out_dir)\n",
    "        plot_record_decomposition(rec, DECOMPOSITION_METHOD, DECOMPOSITION_OUTPUT_TAG, out_dir)\n",
    "        plot_record_beats(rec, SEPARATION_METHOD, out_dir)\n",
    "        plot_record_resp_cycles(rec, RESP_CYCLES_OUTPUT_TAG, out_dir)\n",
    "\n",
    "\n",
    "export_all_record_figures(records)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
